{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read MNIST dataset\n",
    "The dataset could be downloaded from http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "## The raw data format:\n",
    "* image:  28 x 28 integer [0,1]\n",
    "* label: integer [0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5;    shape of image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABjCAYAAAD0H3xZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACKxJREFUeJztnXtsVGkZh59fC5RryMhNXEHWDaAEY6WlSoBsRURFE0DYjWRRE4is4K4LQWLFhHBJsFFRIBC1yFI20cgdxGCWQFYiCVAqLMtyKS5rkcrFEgELoZgyr3+cc+jQbZnpzPSbTjlPcjI9Z77LO7++8853vtuRmRHihpxMG/A0EYrtkFBsh4RiOyQU2yGh2A5xJrakL0uqkvSepBJX9aaCpEGS3pJ0XtJZSa/515dJ+pekt/1jckLluWhnS8oFLgJfBGqAE8BMMzvX5pWngKSBwEAzOympF/A3YCrwInDXzH7emvJceXYR8J6ZvW9m/wP+AExxVHfSmNk1Mzvp/10HnAeeSbY8V2I/A1yJOa8hBaMzgaQhwGeA4/6lVyS9I+l1SZFEynAltpq5ljX9BJJ6AjuBBWb2X+BXwHNAPnANWJ1IOa7ErgEGxZx/FLjqqO6UkNQZT+jfmdkuADO7YWYPzSwKbMQLk3FxJfYJYKikZyV1Ab4B/NFR3UkjScAm4LyZ/SLm+sCYZNOAdxMpr1N6zWseM2uQ9ArwJpALvG5mZ13UnSJjgW8CZyS97V9bAsyUlI8XCquBlxMpzEnTL8QjvIN0SCi2Q0KxHRKK7RDnYkua67rOdJKK/SmJnWRPXlaLTQr2Jy2235O3AfgKMAKv7Tki2fKeBpJuZ0saAywzsy/55z8CMLOftJSnb9++1qNHD/r165dUne2B2traD9hfXV3NzZs3m+v/eYxU7iCb68n7bNNEfoybCzB48GAuX76cQpXtk8LCwoTSpRKzE+rJM7MyMys0s8Js9uh0kIrYWduTlylSETsre/IySdIxO4t78jJGSl2sZrYf2J8mWzo84e26Q0KxHRKK7RAnw2KuiEajADx48OAD723ZsgWAe/fuAXDunDc/aM2aNQAsWbIEgPXr1wPQrVs3AFav9gbO582bl7J9oWc7JKs8+86dOwA8fPgQgNOnTwNw4MABAG7fvg1AWVlZ3LKGDBkCwKJFiwDYtGkTAL179wZg/PjxAEyYMCEdpgOhZzslKzy7pqYGgPz8fABu3bqVdFk5OZ5/BZ4cxOY5c+YA0L9/fwB69uwJkNYeytCzHZIVnt2nTx8ABgwYACTm2ZMmTXos765duwDIy8sDoLi4ON1mxiX0bIdkhWcHcbW8vByAHTt2ADBmzBgApk+f/lj6cePGsXfvXgC6dOkCwPXr1wFYu3Ztm9vbEqFnu8TMnB0FBQWWDurr662+vt6i0ahFo1ErKSmxkpISy8nJsZycHDt8+HBa6kkU/3PF/fyhZzskK8XOy8sjLy8PSUgiEokQiTSutFi3bt0jb2pPZKXY2UpWtEbisWDBAgAqKioA2L17N2fPeiN0I0eOzJhdTQk92yEdwrODtnTQ23fo0CGmTPGWWU6dOhWAsWPHAjBt2jQAvOUyjkmkyZKuI11Nv3gcP37cIpGIRSKRR83B4CgvL7fy8nKrq6uzurq6tNQXNv3aIR0ijDSlqKjo0Q/kwoULAdi+fTsAs2fPBuDSpUsALF68GIBevXq1uV2hZzvE6dK8wsJCq6ysdFYfQH19PQDHjh0DYOLEiQCPbnhmzJgBwNatW5Ouo7CwkMrKyri/uKFnO6RDxuxYunbtCjQOFuTm5gLQ0NAAwJ49ewCoqqoCYPjw4W1mS+jZDumwnn31qjdVPBgOO3r0KNDo0QGjR48GYNiwYW1uU+jZDonr2ZIGAW8AHwaiQJmZrZX0IWArMARvZ4IXzSz5OQZpoLa2FoANGzawefNmoHEaRFOC2B1M1nFx+56IZzcAi8zsk8DngO/5S/BKgENmNhQ45J+HPIG4nm1m1/C25sHM6iQFm1JNAYr9ZFuAvwA/bBMrW+Du3bsA7Nu3D4AVK1YAcPHixRbzBNPJSktLASgoKGhLEx+jVTG7yaZUA/x/RPAP6d9CnrmSKiVVBl/zp5WEWyNNN6VKNMaZWRlQBt4dZDJGBgTTfa9c8ZZfzpo1C4BTp061mCeYrLN8+XKgsfWRiS7WhDy7uU2pgBvBXkn+67/bxsSOQyKtkWY3pcJbhvdtoNR/3Ztu4+7fvw80DnsdOXIEgAsXLjwx3+TJk1m6dCnQOBmzc+fO6Tav1SQSRlralKoU2CZpDvBP4IW2MbHjkEhr5AjNL50G+EI6jamurgZg1apVABw8eBAg7nr37t27A7By5UoA5s+f/2iorD0R3kE6pF31jezcuRNonKjelFGjRgEwc+ZMADp18syfO9fbbyXo4WuvhJ7tkkRGhdN1uBpdd004ut4OCcV2SCi2Q0KxHRKK7RCn80Yk1QIdb/sz+JiZxV2dGu6f7ZAwjDgkFNshodgOyYjYkkzS6pjzH0halqayyyXNSEdZzZSd1DPFAjLl2Q+Ar0vqm6H6m8XfOTkevzSzfP9o1TZ7mRK7AW8QeGHTN5p6pqS7/muxpMOStkm6KKlU0kuSKiSdkfRcTDETJf3VT/c1P3+upJ9JOuE/purlmHLfkvR74ExbfuhMxuwNwEuSerciz6eB14BP4Q3VDTOzIuC3wKsx6YYAzwNfBX4tqSswB7hjZqOB0cB3JD3rpy8CfmxmIwAk7Zf0kRZsaPUzxQIyJrZ5z+h6A/h+K7KdMO9Jdg+AS8AB//oZPIEDtplZ1Mz+DrwPfAKYBHzLH0c9DvQBhvrpK8zsHzG2TTaz5jbxTeqZYgGZHqlZA5wENsdca8B3An9kP3YwMXYPuWjMeZTHP0vTOzXDG0d91czejH1DUjFwLxFjzexGTL6NwJ8SyReQ0aafmf0H2Ib3FQ+oBoI5YVOAZOYgvCApx4/jHweq8DbonefPgUHSMEk9WlNoss8UC2gP7ezVQGyrZCPwvKQKvJ3mE/K6JlQBh4E/A981s3q8uH4OOCnpXeA3tPDNfkLM/qn/Y/wO8Hma+YF/EmHfiEPag2c/NYRiOyQU2yGh2A4JxXZIKLZDQrEd8n/tKCIULEAH9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    type dataset: string\n",
    "    type path: string\n",
    "    rtype: tuple (int, 2d array)\n",
    "    \n",
    "    * Python function for importing the MNIST data set. \n",
    "    * It returns an iterator of 2-tuples\n",
    "    * The first element is the label\n",
    "    * The second element is a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    #for i in range(len(lbl)):\n",
    "    #    yield get_img(i)\n",
    "    return (lbl, img)\n",
    "\n",
    "def show(label, image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure(figsize=(1,1))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.set_xlabel(\"Number: %d\" % label)\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "labels, images = read('training', './data')\n",
    "label, image = labels[0], images[0]\n",
    "print(\"label: %d;   \" % label, \"shape of image: (%s, %s)\" %image.shape)\n",
    "show(label, image)\n",
    "\n",
    "images = images.reshape(-1,28*28)\n",
    "one_hot_labels = np.zeros([labels.shape[0],10])\n",
    "for i in range(len(labels)):\n",
    "    one_hot_labels[i][labels[i]] = 1\n",
    "    \n",
    "\n",
    "test_labels, test_images = read('testing', './data')\n",
    "test_images = test_images.reshape(-1,28*28)\n",
    "test_one_hot_labels = np.zeros([test_labels.shape[0],10])\n",
    "for i in range(len(test_labels)):\n",
    "    test_one_hot_labels[i][test_labels[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow KMeans\n",
    "Use TensorFlow built-in KMeans algorithm: https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans#training_graph\n",
    "\n",
    "\n",
    "\n",
    "Important Setups\n",
    "* **Input placeholder X**: Flatten 28 x 28 pixels to a vector\n",
    "* **label placeholder Y**: one hot encoder for label (this is not for Kmeans, but defined here for later usage)\n",
    "* **number of clusters**\n",
    "* **initial clusters**: \n",
    "    * *random*:    choose centers randomly from 'inputs'\n",
    "    * *kmean++*:    use kmean++ to choose centers from 'inputs'\n",
    "    * *kmc2*:    use the fast k-MC2 algorithm to choos centers from 'inputs'\n",
    "* **distance metric**: squared euclidean distance\n",
    "* **mini batch steps**: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.factorization import KMeans\n",
    "\n",
    "n_features = 28*28\n",
    "n_classes = 10\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_features])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "\n",
    "#%% create an object for generating KMeans clustering graph\n",
    "kmeans = KMeans(inputs=X, num_clusters=25, distance_metric='cosine', initial_clusters='kmeans_plus_plus',\n",
    "                use_mini_batch=True, mini_batch_steps_per_iteration=2)\n",
    "\n",
    "#%% build graph\n",
    "(all_scores, cluster_idx, scores, cluster_centers_initialized, init_op, training_op) = kmeans.training_graph()\n",
    "avg_distance = tf.reduce_mean(scores)\n",
    "\n",
    "cluster_idx = cluster_idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Graph\n",
    "Zoom in graph for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = 'D:/Documents/codes/python/python_classification_series/tensorboard_log'\n",
    "writer = tf.summary.FileWriter(graph, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic](tensorboard_kmeans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tensorFlow to do clustering\n",
    "\n",
    "Step 1:\n",
    "Initialization. \n",
    "Run tf.global_variables_initializer will initialize all global variables as well as placeholders.\n",
    "\n",
    "Step 2: \n",
    "training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Avg Distance: 0.317378\n",
      "Step 4, Avg Distance: 0.227988\n",
      "Step 8, Avg Distance: 0.219860\n",
      "Step 12, Avg Distance: 0.217612\n",
      "Step 16, Avg Distance: 0.216873\n",
      "Step 20, Avg Distance: 0.216542\n",
      "Step 24, Avg Distance: 0.216321\n",
      "Step 28, Avg Distance: 0.216155\n",
      "Step 32, Avg Distance: 0.216055\n",
      "Step 36, Avg Distance: 0.215992\n",
      "Step 40, Avg Distance: 0.215949\n",
      "Step 44, Avg Distance: 0.215916\n",
      "Step 48, Avg Distance: 0.215897\n"
     ]
    }
   ],
   "source": [
    "n_steps = 50\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(init_op, feed_dict={X:images})\n",
    "\n",
    "for i in range(1, n_steps + 1):\n",
    "    _, d, idx = sess.run([training_op, avg_distance, cluster_idx],\n",
    "                     feed_dict={X:images})\n",
    "    if i % 4 == 0 or i == 1:\n",
    "        print(\"Step %i, Avg Distance: %f\" % (i, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.74180\n"
     ]
    }
   ],
   "source": [
    "# Assign a label to each centroid\n",
    "# Count total number of labels per centroid, using the label of each training\n",
    "# sample to their closest centroid (given by 'idx')\n",
    "counts = np.zeros(shape=(25, 10))\n",
    "for i in range(len(idx)):\n",
    "    counts[idx[i]] += one_hot_labels[i]\n",
    "# Assign the most frequent label to the centroid\n",
    "labels_map = [np.argmax(c) for c in counts]\n",
    "labels_map = tf.convert_to_tensor(labels_map)\n",
    "\n",
    "# Evaluation ops\n",
    "# Lookup: centroid_id -> label\n",
    "cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
    "\n",
    "# Compute accuracy\n",
    "correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Test Model\n",
    "print(\"Test Accuracy: %.5f\" % sess.run(accuracy_op, feed_dict={X: test_images, Y: test_one_hot_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
